{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB,MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "wnlem=WordNetLemmatizer()\n",
    "df=pd.read_csv(\"twitter_analysis.csv\",encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['class','id','Date-Time','Query','User','Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>id</th>\n",
       "      <th>Date-Time</th>\n",
       "      <th>Query</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class          id                     Date-Time     Query           User  \\\n",
       "0      0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
       "1      0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
       "2      0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
       "3      0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
       "4      0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
       "\n",
       "                                               Tweet  \n",
       "0  is upset that he can't update his Facebook by ...  \n",
       "1  @Kenichan I dived many times for the ball. Man...  \n",
       "2    my whole body feels itchy and like its on fire   \n",
       "3  @nationwideclass no, it's not behaving at all....  \n",
       "4                      @Kwesidei not the whole crew   "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class']=np.where(df['class']==4,1,0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you',\n",
       "       \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself',\n",
       "       'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her',\n",
       "       'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them',\n",
       "       'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom',\n",
       "       'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are',\n",
       "       'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n",
       "       'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and',\n",
       "       'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at',\n",
       "       'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
       "       'through', 'during', 'before', 'after', 'above', 'below', 'to',\n",
       "       'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under',\n",
       "       'again', 'further', 'then', 'once', 'here', 'there', 'when',\n",
       "       'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
       "       'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own',\n",
       "       'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will',\n",
       "       'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll',\n",
       "       'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn',\n",
       "       \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\",\n",
       "       'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma',\n",
       "       'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\",\n",
       "       'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\",\n",
       "       'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords=np.array(stopwords.words('english'))\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BridgetsBeaches Thank you for letting people know, but now I'm sad that the direct message I got wasn't actually from Bridget \n",
      "ooooh.... LOL  that leslie.... and ok I won't do it again so leslie won't  get mad again \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['@alielayus I want to go to promote GEAR AND GROOVE but unfornately no ride there  I may b going to the one in Anaheim in May though',\n",
       " 'thought sleeping in was an option tomorrow but realizing that it now is not. evaluations in the morning and work in the afternoon! ',\n",
       " '@julieebaby awe i love you too!!!! 1 am here  i miss you',\n",
       " '@HumpNinja I cry my asian eyes to sleep at night ',\n",
       " \"ok I'm sick and spent an hour sitting in the shower cause I was too sick to stand and held back the puke like a champ. BED now \",\n",
       " '@cocomix04 ill tell ya the story later  not a good day and ill be workin for like three more hours...',\n",
       " '@MissXu sorry! bed time came here (GMT+1)   http://is.gd/fNge',\n",
       " \"@fleurylis I don't either. Its depressing. I don't think I even want to know about the kids in suitcases. \",\n",
       " \"Bed. Class 8-12. Work 12-3. Gym 3-5 or 6. Then class 6-10. Another day that's gonna fly by. I miss my girlfriend \",\n",
       " \"really don't feel like getting up today... but got to study to for tomorrows practical exam... \"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=list(df.Tweet)\n",
    "print(df['Tweet'].loc[136])\n",
    "print(df['Tweet'].loc[27])\n",
    "text[30:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user=r'@[^\\s]+'\n",
    "url=r'((http://)[^ ]*|(https://)[^ ]*|(www.)[^ ]*)'\n",
    "pattern=r'([^a-zA-z0-9 ]*)'\n",
    "numbers=r'(\\d+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text=[]\n",
    "for tweet in text:\n",
    "    tweet=tweet.lower()\n",
    "    tweet=re.sub(url,\"url\",tweet)\n",
    "    tweet=re.sub(user,\"\",tweet)\n",
    "    tweet=re.sub(pattern,\"\",tweet)\n",
    "    tweet=re.sub(numbers,\"\",tweet)\n",
    "    lemm_tweet=\"\"\n",
    "    for word in tweet.split( ):\n",
    "        if word not in stopwords:\n",
    "            word=wnlem.lemmatize(word)\n",
    "            lemm_tweet=lemm_tweet+word+\"  \"\n",
    "        else:\n",
    "            lemm_tweet=lemm_tweet+word+\" \"\n",
    "    processed_text.append(lemm_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i want  to go  to promote  gear  and groove  but unfornately  no ride  there i may  b  going  to the one  in anaheim  in may  though  ',\n",
       " 'thought  sleeping  in was an option  tomorrow  but realizing  that it now is not evaluation  in the morning  and work  in the afternoon  ',\n",
       " 'awe  i love  you too am here i miss  you ',\n",
       " 'i cry  my asian  eye  to sleep  at night  ',\n",
       " 'ok  im  sick  and spent  an hour  sitting  in the shower  cause  i was too sick  to stand  and held  back  the puke  like  a champ  bed  now ',\n",
       " 'ill  tell  ya  the story  later  not a good  day  and ill  be workin  for like  three  more hour  ',\n",
       " 'sorry  bed  time  came  here gmt  url  ',\n",
       " 'i dont  either  its depressing  i dont  think  i even  want  to know  about the kid  in suitcase  ',\n",
       " 'bed  class  work  gym  or then class  another  day  thats  gonna  fly  by i miss  my girlfriend  ',\n",
       " 'really  dont  feel  like  getting  up today  but got  to study  to for tomorrow  practical  exam  ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text[30:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken : 7.4 minutes\n"
     ]
    }
   ],
   "source": [
    "time2=time.time()\n",
    "print(\"Time Taken :\",round(time2-time1)/60,\"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>id</th>\n",
       "      <th>Date-Time</th>\n",
       "      <th>Query</th>\n",
       "      <th>User</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset  that he cant  update  his facebook  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>i dived  many  time  for the ball  managed  to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole  body  feel  itchy  and like  its on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>no its not behaving  at all im  mad  why am i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>not the whole  crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class          id                     Date-Time     Query           User  \\\n",
       "0      0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
       "1      0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
       "2      0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
       "3      0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
       "4      0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
       "\n",
       "                                      processed_text  \n",
       "0  is upset  that he cant  update  his facebook  ...  \n",
       "1  i dived  many  time  for the ball  managed  to...  \n",
       "2  my whole  body  feel  itchy  and like  its on ...  \n",
       "3  no its not behaving  at all im  mad  why am i ...  \n",
       "4                              not the whole  crew    "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_text']=processed_text\n",
    "df.drop(columns=['Tweet'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          is upset  that he cant  update  his facebook  ...\n",
       "1          i dived  many  time  for the ball  managed  to...\n",
       "2          my whole  body  feel  itchy  and like  its on ...\n",
       "3          no its not behaving  at all im  mad  why am i ...\n",
       "4                                      not the whole  crew  \n",
       "                                 ...                        \n",
       "1599994    just woke  up having no school  is the best  f...\n",
       "1599995    thewdbcom  very cool  to hear  old  walt  inte...\n",
       "1599996    are you ready  for your mojo  makeover  ask  m...\n",
       "1599997    happy  th  birthday  to my boo  of alll  time ...\n",
       "1599998                              happy  charitytuesday  \n",
       "Name: processed_text, Length: 1599999, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['processed_text']\n",
    "X=df[cols]\n",
    "y=df['class']\n",
    "X_train,X_test,y_train,y_test=train_test_split(df['processed_text'],df['class'],random_state=0,test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429405     im  free  now and welcome  for graduation  no ...\n",
       "399143     will be in congo  during political  election  ...\n",
       "1221496        omg  my shower  was too refreshing  i think  \n",
       "881682             on my way  back  home  tonight  was fun  \n",
       "1161833     on sunsetttt  after a fun  night  at ucla  with \n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429405     im  free  now and welcome  for graduation  no ...\n",
      "399143     will be in congo  during political  election  ...\n",
      "1221496        omg  my shower  was too refreshing  i think  \n",
      "881682             on my way  back  home  tonight  was fun  \n",
      "1161833     on sunsetttt  after a fun  night  at ucla  with \n",
      "Name: processed_text, dtype: object \n",
      "\n",
      "429405     0\n",
      "399143     0\n",
      "1221496    1\n",
      "881682     1\n",
      "1161833    1\n",
      "Name: class, dtype: int32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1519999,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.head(),\"\\n\")\n",
    "print(y_train.head())\n",
    "X_train.shape\n",
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive count  800000\n",
      "Negative count  799999\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive count \",len(df[df['class']==1]))\n",
    "print(\"Negative count \",len(df[df['class']==0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken  3  minutes\n"
     ]
    }
   ],
   "source": [
    "time5=time.time()\n",
    "tf=TfidfVectorizer(ngram_range=(1,3)).fit(X_train)\n",
    "x_train_transform=tf.transform(X_train)\n",
    "x_test_transform=tf.transform(X_test)\n",
    "vocab=tf.vocabulary_.keys()\n",
    "#vocab\n",
    "time6=time.time()\n",
    "print(\"Time Taken \",round((time6-time5)/60),\" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12256866"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=np.array(tf.get_feature_names())\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score  0.8261125\n",
      "Time Taken  16  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Ananaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "time3=time.time()\n",
    "lsvc=LinearSVC()\n",
    "lsvc.fit(x_train_transform,y_train)\n",
    "acc_score=lsvc.score(x_test_transform,y_test)\n",
    "print(\"Accuracy Score \",acc_score)\n",
    "time4=time.time()\n",
    "print(\"Time Taken \",round((time4-time3)/60),\" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33629  6357]\n",
      " [ 7554 32460]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8261177155744202"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lsvc=lsvc.predict(x_test_transform)\n",
    "cm_lsvc=confusion_matrix(y_test,y_pred_lsvc)\n",
    "roc_score_lsvc=roc_auc_score(y_test,y_pred_lsvc)\n",
    "print(cm_lsvc)\n",
    "roc_score_lsvc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83     39986\n",
      "           1       0.84      0.81      0.82     40014\n",
      "\n",
      "    accuracy                           0.83     80000\n",
      "   macro avg       0.83      0.83      0.83     80000\n",
      "weighted avg       0.83      0.83      0.83     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_lsvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive features : ['dont have to' 'not bad' 'no problem' 'not so bad' 'not sad'\n",
      " 'doesnt have to' 'cannot wait' 'doesnt hurt' 'no worry' 'excited']\n",
      "Negative features : ['sad' 'miss' 'poor' 'cant' 'missing' 'rip' 'sick' 'sadly' 'unfortunately'\n",
      " 'died']\n"
     ]
    }
   ],
   "source": [
    "coef=np.array(lsvc.coef_[0].argsort())\n",
    "negative_=features[coef[:10]]\n",
    "positive_=features[coef[-11:-1][::-1]]\n",
    "print(\"Positive features :\",positive_)\n",
    "print(\"Negative features :\",negative_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score  0.8241625 \n",
      "\n",
      "Time Taken  15  minutes\n"
     ]
    }
   ],
   "source": [
    "time5=time.time()\n",
    "lg=LogisticRegression(C=1,random_state=0,max_iter=10000)\n",
    "lg.fit(x_train_transform,y_train)\n",
    "acc_score=lg.score(x_test_transform,y_test)\n",
    "print(\"Accuracy Score \",acc_score,\"\\n\")\n",
    "time6=time.time()\n",
    "print(\"Time Taken \",round((time6-time5)/60),\" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33462  6524]\n",
      " [ 7543 32471]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8241669365854497"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lg=lg.predict(x_test_transform)\n",
    "cm_lg=confusion_matrix(y_test,y_pred_lg)\n",
    "roc_score_lg=roc_auc_score(y_test,y_pred_lg)\n",
    "print(cm_lg)\n",
    "roc_score_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83     39986\n",
      "           1       0.83      0.81      0.82     40014\n",
      "\n",
      "    accuracy                           0.82     80000\n",
      "   macro avg       0.82      0.82      0.82     80000\n",
      "weighted avg       0.82      0.82      0.82     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive features : ['yay' 'smile' 'love' 'good' 'excited' 'awesome' 'happy' 'dont have to'\n",
      " 'not bad' 'no problem']\n",
      "Negative features : ['sad' 'miss' 'poor' 'cant' 'sick' 'missing' 'hate' 'rip' 'suck' 'sadly']\n"
     ]
    }
   ],
   "source": [
    "coef=np.array(lg.coef_[0].argsort())\n",
    "negative_=features[coef[:10]]\n",
    "positive_=features[coef[-11:-1]]\n",
    "print(\"Positive features :\",positive_)\n",
    "print(\"Negative features :\",negative_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score  0.7983875 \n",
      "\n",
      "Time Taken  0  minutes\n"
     ]
    }
   ],
   "source": [
    "time5=time.time()\n",
    "bnb=BernoulliNB(alpha=2)\n",
    "bnb.fit(x_train_transform,y_train)\n",
    "acc_score=bnb.score(x_test_transform,y_test)\n",
    "print(\"Accuracy Score \",acc_score,\"\\n\")\n",
    "time6=time.time()\n",
    "print(\"Time Taken \",round((time6-time5)/60),\" minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score  0.8059875 \n",
      "\n",
      "Time Taken  0  minutes\n"
     ]
    }
   ],
   "source": [
    "time5=time.time()\n",
    "mnb=MultinomialNB(alpha=2)\n",
    "mnb.fit(x_train_transform,y_train)\n",
    "acc_score=mnb.score(x_test_transform,y_test)\n",
    "print(\"Accuracy Score \",acc_score,\"\\n\")\n",
    "time6=time.time()\n",
    "print(\"Time Taken \",round((time6-time5)/60),\" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30428,  9558],\n",
       "       [ 6571, 33443]], dtype=int64)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=bnb.predict(x_test_transform)\n",
    "cm_bnb=confusion_matrix(y_test,y_pred)\n",
    "cm_bnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score  0.6768375 \n",
      "\n",
      "Time Taken  31  minutes\n"
     ]
    }
   ],
   "source": [
    "time7=time.time()\n",
    "gbc=GradientBoostingClassifier()\n",
    "gbc.fit(x_train_transform,y_train)\n",
    "acc_score_gbc=gbc.score(x_test_transform,y_test)\n",
    "print(\"Accuracy Score \",acc_score_gbc,\"\\n\")\n",
    "time8=time.time()\n",
    "print(\"Time Taken \",round((time8-time7)/60),\" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
